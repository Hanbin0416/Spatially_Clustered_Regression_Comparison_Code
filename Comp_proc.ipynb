{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "614bcc47-a7b6-4f1a-ac51-ef0301f453f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Sequence, Mapping, Optional, Dict, Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "import geopandas as gpd\n",
    "from libpysal import weights\n",
    "from libpysal.weights import Queen, Rook\n",
    "import spreg\n",
    "from spreg import OLS as PYSAL_OLS\n",
    "from spreg.skater_reg import Skater_reg\n",
    "from mgwr.sel_bw import Sel_BW\n",
    "from mgwr.gwr import MGWR\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Guo_et_al\"\n",
    ")\n",
    "import Algorithm9\n",
    "from Algorithm9 import kmodels, split_components, greedy_merge\n",
    "import Network9\n",
    "from Network9 import Test_Equations, regression_error\n",
    "import GridData9\n",
    "from GridData9 import *\n",
    "np.random.seed(0)\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24165160-7d20-428d-a5cd-c8b1efb4f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(\n",
    "    dirs: Sequence[str],\n",
    "    file_names: Sequence[str],\n",
    "    fields: Sequence[str],\n",
    "    *,\n",
    "    ncols = 2,\n",
    "    colorbar = False,\n",
    "    cmap = \"viridis\",\n",
    "    fig_size = (3, 3),\n",
    "):\n",
    "\n",
    "    entries: list[tuple[np.ndarray, str]] = []  # (grid, title)\n",
    "\n",
    "    for d in dirs:\n",
    "        d_base = os.path.basename(d.rstrip(\"/\\\\\"))\n",
    "        for fname in file_names:\n",
    "            path = os.path.join(d, fname)\n",
    "            df = pd.read_csv(path, sep=\"\\t\")\n",
    "            \n",
    "            side_x = int(df[\"u\"].max()) + 1\n",
    "            side_y = int(df[\"v\"].max()) + 1\n",
    "\n",
    "            df_sorted = df.sort_values([\"v\", \"u\"])\n",
    "            file_stem = os.path.splitext(fname)[0]\n",
    "            base_title = f\"{d_base} | {file_stem}\"\n",
    "\n",
    "            for field in fields:\n",
    "                arr = df_sorted[field].to_numpy()\n",
    "                grid = arr.reshape((side_y, side_x))\n",
    "                entries.append((grid, f\"{base_title}\\n{field}\"))\n",
    "\n",
    "    if not entries:\n",
    "        raise ValueError(\"No valid (dir, file, field) entries to plot.\")\n",
    "\n",
    "    nplots = len(entries)\n",
    "    nrows = int(np.ceil(nplots / ncols))\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows, ncols,\n",
    "        figsize=(fig_size[0] * ncols, fig_size[1] * nrows),\n",
    "        #figsize=(12,12),\n",
    "        squeeze=False\n",
    "    )\n",
    "\n",
    "    for i, (grid, title) in enumerate(entries):\n",
    "        ax = axes[i // ncols, i % ncols]\n",
    "        im = ax.imshow(grid, origin=\"lower\", cmap=cmap)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        if colorbar:\n",
    "            plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "    for j in range(i + 1, nrows * ncols):\n",
    "        fig.delaxes(axes[j // ncols, j % ncols])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d9797-d205-4613-8bf6-8928fd86b6c0",
   "metadata": {},
   "source": [
    "### Guo et al (Kmodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a197b1e-2a01-4487-8d13-22b55aa51bf2",
   "metadata": {},
   "source": [
    "Test for 1 feat continuous GFS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beae7fde-5254-4e89-93e1-8f8944306cd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Pos_Encode(r,c,side):\n",
    "    return r*side+c\n",
    "\n",
    "def Pos_Decode(code,side):\n",
    "    return code//side, code%side\n",
    "\n",
    "def run_kmodels(data_dir, file_names,\n",
    "                n_regions=5, micro_clusters=None, min_region=20,\n",
    "                save_region_label=False, verbose=True,\n",
    "                output_dir=None):\n",
    "\n",
    "    if micro_clusters is None:\n",
    "        micro_clusters = 2 * n_regions\n",
    "\n",
    "    results = {}\n",
    "    for fname in file_names:\n",
    "            df = pd.read_csv(os.path.join(data_dir, fname), sep=\"\\t\")\n",
    "\n",
    "            X = df[[\"feat1\", \"feat2\"]].to_numpy()\n",
    "            y = df[\"y\"].to_numpy()\n",
    "            # Xs = preprocessing.StandardScaler().fit_transform(X)\n",
    "            # ys = preprocessing.StandardScaler().fit_transform(y.reshape(-1, 1)).ravel()\n",
    "            Xarr = np.hstack([np.ones((len(y), 1)), X])\n",
    "            Yarr = y\n",
    "\n",
    "            side_x = int(df[\"u\"].max()) + 1\n",
    "            side_y = int(df[\"v\"].max()) + 1\n",
    "            \n",
    "            w = weights.lat2W(side_y, side_x).symmetrize()\n",
    "\n",
    "            # --- KModels → split → merge ---\n",
    "            clabel, _ = kmodels(Xarr, Yarr, micro_clusters, w, init_stoc_step=False, verbose=False)\n",
    "            slabel    = split_components(w, clabel)\n",
    "            rlabel, rcoeff, _ = greedy_merge(Xarr, Yarr, n_regions, w, slabel,\n",
    "                                             min_size=min_region, verbose=False)\n",
    "\n",
    "            coefs = np.vstack([rcoeff[lab] for lab in rlabel])\n",
    "            df_out = df.copy()\n",
    "            df_out[\"a1_result\"] = coefs[:, 1]\n",
    "            df_out[\"a2_result\"] = coefs[:, 2]\n",
    "            df_out[\"b_result\"]  = coefs[:, 0]\n",
    "            if save_region_label:\n",
    "                df_out[\"region_label\"] = rlabel\n",
    "\n",
    "            out_name = fname.replace(\".txt\", \"_KM_result.txt\")\n",
    "            out_path = os.path.join(out_dir, out_name)\n",
    "            df_out.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "            if verbose:\n",
    "                print(f\"[OK] {out_path}\")\n",
    "\n",
    "            results[fname] = df_out\n",
    "    return results, rcoeff, rlabel, coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2245b12-f61d-4671-bbc7-e7117b761eae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/KM\\df_con_uni_KM_result.txt\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/KM\\df_con_grf_KM_result.txt\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/KM\\df_discon_uni_KM_result.txt\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/KM\\df_discon_grf_KM_result.txt\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/KM\\df_multi_uni_KM_result.txt\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/KM\\df_multi_grf_KM_result.txt\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/KM\\df_vor_grf_KM_result.txt\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/KM\\df_vor_uni_KM_result.txt\n"
     ]
    }
   ],
   "source": [
    "#df = r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Data_gen\"\n",
    "data_dir   = r\"D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_gen\"\n",
    "file_names = [\n",
    "    \"df_con_uni.txt\",\n",
    "    \"df_con_grf.txt\",\n",
    "    \"df_discon_uni.txt\",\n",
    "    \"df_discon_grf.txt\",\n",
    "    \"df_multi_uni.txt\",\n",
    "    \"df_multi_grf.txt\",\n",
    "    \"df_vor_grf.txt\",\n",
    "    \"df_vor_uni.txt\"\n",
    "]\n",
    "out_dir = r\"D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/KM\"\n",
    "res = run_kmodels(n_regions=10, data_dir = data_dir,file_names = file_names, output_dir = out_dir,save_region_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac288510-2c7c-4242-9b77-37f4a217a86c",
   "metadata": {},
   "source": [
    "### Skater Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4d2a7fb2-d58f-4850-9439-a4ef0c779193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_skreg(\n",
    "    data_dir: str,\n",
    "    file_names: Sequence[str] | str,\n",
    "    n_regions = 5,\n",
    "    quorum = 20,\n",
    "    save_region_label = False,\n",
    "    output_dir = None,\n",
    "    verbose = False,\n",
    "):\n",
    "    if isinstance(file_names, str):\n",
    "        files = [file_names]\n",
    "    else:\n",
    "        files = list(file_names)\n",
    "\n",
    "    out_dir = os.path.join(data_dir, output_dir) if output_dir else data_dir\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    results: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for fname in files:\n",
    "        path = os.path.join(data_dir, fname)\n",
    "        df = pd.read_csv(path, sep=\"\\t\")\n",
    "        #feat_cols = [c for c in df if c.startswith(\"feat\")]\n",
    "        X = df[[\"feat1\", \"feat2\"]].to_numpy()\n",
    "        y = df[\"y\"].to_numpy()\n",
    "\n",
    "        side_x = int(df[\"u\"].max()) + 1\n",
    "        side_y = int(df[\"v\"].max()) + 1\n",
    "        w = weights.lat2W(side_y, side_x).symmetrize()\n",
    "        X_std = StandardScaler().fit_transform(X)\n",
    "        #y_std = StandardScaler().fit_transform(y.reshape(-1, 1)).ravel()\n",
    "        \n",
    "        skater = Skater_reg()\n",
    "        res = skater.fit(\n",
    "            n_regions,\n",
    "            w,\n",
    "            X_std,                                \n",
    "            {\"reg\": PYSAL_OLS, \"y\": y, \"x\": X},\n",
    "            quorum=quorum,\n",
    "            verbose=False\n",
    "        )\n",
    "        labels = res._trace[-1][0].astype(int)\n",
    "        # each sklearn regiems regression\n",
    "        region_coefs: dict[int, np.ndarray] = {}\n",
    "        for r in np.unique(labels):\n",
    "            idx = (labels == r)\n",
    "            Xr, yr = X[idx, :], y[idx]\n",
    "            lr = LinearRegression(fit_intercept=True).fit(Xr, yr)\n",
    "            region_coefs[r] = np.array([lr.intercept_, *lr.coef_])  # [b, a1, a2]\n",
    "\n",
    "        coefs = np.vstack([region_coefs[int(lab)] for lab in labels])  # (N,3)\n",
    "        df_out = df.copy()\n",
    "        df_out[\"b_result\"]  = coefs[:, 0]\n",
    "        df_out[\"a1_result\"] = coefs[:, 1]\n",
    "        df_out[\"a2_result\"] = coefs[:, 2]\n",
    "        if save_region_label:\n",
    "            df_out[\"region_label\"] = labels\n",
    "\n",
    "        out_name = fname.replace(\".txt\", \"_SKREG_result.txt\")\n",
    "        out_path = os.path.join(out_dir, out_name)\n",
    "        df_out.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "        if verbose:\n",
    "            print(f\"[OK] {out_path}\")\n",
    "        results[fname] = df_out\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c553831e-e61b-4e67-ad86-6a13ea80889d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[203], line 14\u001b[0m\n\u001b[0;32m      2\u001b[0m out_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/SKREG\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m files \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_con_uni.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_con_grf.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_vor_uni.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m ]\n\u001b[1;32m---> 14\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mrun_skreg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_regions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquorum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_region_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[202], line 49\u001b[0m, in \u001b[0;36mrun_skreg\u001b[1;34m(data_dir, file_names, n_regions, quorum, save_region_label, output_dir, verbose)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#y_std = StandardScaler().fit_transform(y.reshape(-1, 1)).ravel()\u001b[39;00m\n\u001b[0;32m     48\u001b[0m skater \u001b[38;5;241m=\u001b[39m Skater_reg()\n\u001b[1;32m---> 49\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mskater\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_regions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                                \u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPYSAL_OLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquorum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquorum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     56\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m labels \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39m_trace[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# each sklearn regiems regression\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Program Files\\Python 3.12.4\\Lib\\site-packages\\spreg\\skater_reg.py:290\u001b[0m, in \u001b[0;36mSkater_reg.fit\u001b[1;34m(self, n_clusters, W, data, data_reg, quorum, trace, islands, verbose, model_family)\u001b[0m\n\u001b[0;32m    282\u001b[0m prev_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current_n_subtrees \u001b[38;5;241m<\u001b[39m n_clusters:  \u001b[38;5;66;03m# while we don't have enough regions\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     (\n\u001b[0;32m    285\u001b[0m         best_deletion,\n\u001b[0;32m    286\u001b[0m         trees_scores,\n\u001b[0;32m    287\u001b[0m         new_MSF,\n\u001b[0;32m    288\u001b[0m         current_n_subtrees,\n\u001b[0;32m    289\u001b[0m         current_labels,\n\u001b[1;32m--> 290\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_cut\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mMSF\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_n_subtrees\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquorum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquorum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrees_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrees_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_family\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_family\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(best_deletion\u001b[38;5;241m.\u001b[39mscore):  \u001b[38;5;66;03m# if our search succeeds\u001b[39;00m\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;66;03m# accept the best move as *the* move\u001b[39;00m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m super_verbose:\n",
      "File \u001b[1;32mD:\\Program Files\\Python 3.12.4\\Lib\\site-packages\\spreg\\skater_reg.py:643\u001b[0m, in \u001b[0;36mSkater_reg.find_cut\u001b[1;34m(self, MSF, data, data_reg, current_n_subtrees, current_labels, quorum, trees_scores, labels, target_label, make, verbose, model_family)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;66;03m# compute the score of these components\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_family \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspreg\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 643\u001b[0m     new_score, new_trees_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_spreg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquorum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_tree\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_family \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatsmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    647\u001b[0m     new_score, new_trees_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_stats(\n\u001b[0;32m    648\u001b[0m         data, data_reg, local_labels, quorum, current_labels, current_tree\n\u001b[0;32m    649\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Program Files\\Python 3.12.4\\Lib\\site-packages\\spreg\\skater_reg.py:421\u001b[0m, in \u001b[0;36mSkater_reg.score_spreg\u001b[1;34m(self, data, data_reg, all_labels, quorum, current_labels, current_tree)\u001b[0m\n\u001b[0;32m    418\u001b[0m         kargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m temp_vars[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myend\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    419\u001b[0m         kargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m temp_vars[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 421\u001b[0m     reg \u001b[38;5;241m=\u001b[39m \u001b[43mdata_reg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m     trees_scores[l] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(reg\u001b[38;5;241m.\u001b[39mu\u001b[38;5;241m.\u001b[39mT, reg\u001b[38;5;241m.\u001b[39mu)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    424\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(trees_scores\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32mD:\\Program Files\\Python 3.12.4\\Lib\\site-packages\\spreg\\ols.py:539\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[1;34m(self, y, x, w, robust, gwk, slx_lags, slx_vars, regimes, sig2n_k, nonspat_diag, spat_diag, moran, white_test, vif, vm, name_y, name_x, name_w, name_gwk, name_ds, latex, **kwargs)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spat_diag:\n\u001b[0;32m    538\u001b[0m     other_end \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _spat_diag_out(\u001b[38;5;28mself\u001b[39m, w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mols\u001b[39m\u001b[38;5;124m'\u001b[39m, moran\u001b[38;5;241m=\u001b[39mmoran)\n\u001b[1;32m--> 539\u001b[0m \u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Program Files\\Python 3.12.4\\Lib\\site-packages\\spreg\\output.py:32\u001b[0m, in \u001b[0;36moutput\u001b[1;34m(reg, vm, other_end, robust, latex)\u001b[0m\n\u001b[0;32m     30\u001b[0m reg\u001b[38;5;241m.\u001b[39msummary \u001b[38;5;241m=\u001b[39m strSummary\n\u001b[0;32m     31\u001b[0m reg\u001b[38;5;241m.\u001b[39m_var_type \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39moutput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 32\u001b[0m \u001b[43mreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mequation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m reg\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequation\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Program Files\\Python 3.12.4\\Lib\\site-packages\\pandas\\core\\frame.py:7183\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   7175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   7176\u001b[0m         \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Series];\u001b[39;00m\n\u001b[0;32m   7177\u001b[0m         \u001b[38;5;66;03m# expected List[ndarray]\u001b[39;00m\n\u001b[0;32m   7178\u001b[0m         keys \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   7179\u001b[0m             Series(k, name\u001b[38;5;241m=\u001b[39mname)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   7180\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m (k, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, by)\n\u001b[0;32m   7181\u001b[0m         ]\n\u001b[1;32m-> 7183\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[43mlexsort_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\n\u001b[0;32m   7185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(by):\n\u001b[0;32m   7187\u001b[0m     \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[0;32m   7189\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label_or_level_values(by[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mD:\\Program Files\\Python 3.12.4\\Lib\\site-packages\\pandas\\core\\sorting.py:366\u001b[0m, in \u001b[0;36mlexsort_indexer\u001b[1;34m(keys, orders, na_position, key, codes_given)\u001b[0m\n\u001b[0;32m    362\u001b[0m         codes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(mask, codes, n \u001b[38;5;241m-\u001b[39m codes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    364\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(codes)\n\u001b[1;32m--> 366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlexsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir = r\".../Data_gen\"\n",
    "out_dir = r\".../Data_result/SKREG\"\n",
    "files = [\n",
    "    \"df_con_uni.txt\",\n",
    "    \"df_discon_uni.txt\",\n",
    "    \"df_multi_uni.txt\",\n",
    "    \"df_vor_uni.txt\"\n",
    "]\n",
    "\n",
    "res = run_skreg(\n",
    "    data_dir=data_dir,\n",
    "    file_names=files,              \n",
    "    n_regions=15,\n",
    "    quorum=20,\n",
    "    save_region_label=False,\n",
    "    output_dir=out_dir,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6dc1c-a285-43c8-81a8-a7a26963c1bd",
   "metadata": {},
   "source": [
    "### MGWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8caa43c3-c816-40ac-8274-33d486a5a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "ArrayLike = Union[np.ndarray, List[float], float]\n",
    "\n",
    "def run_mgwr(\n",
    "    data_dir: str,\n",
    "    file_names: Sequence[str] | str,\n",
    "    *,\n",
    "    feature_cols: Sequence[str],                 \n",
    "    y_col: str = \"y\",\n",
    "    coord_cols: Tuple[str, str] = (\"x_coord\", \"y_coord\"),\n",
    "    output_dir: Optional[str] = None,            \n",
    "    multi: bool = True,                          \n",
    "    fixed: bool = False,                         \n",
    "    kernel: str = \"bisquare\",                   \n",
    "    spherical: bool = False,                     \n",
    "    bws: Optional[ArrayLike] = None,             \n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "\n",
    "    files = [file_names] if isinstance(file_names, str) else list(file_names)\n",
    "    out_dir = data_dir if output_dir is None else output_dir\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    results: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for fname in files:\n",
    "        path = os.path.join(data_dir, fname)\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(path)\n",
    "        df = pd.read_csv(path, sep=\"\\t\")\n",
    "\n",
    "        coords = df.loc[:, coord_cols].to_numpy()\n",
    "        y = df.loc[:, y_col].to_numpy().reshape(-1, 1)\n",
    "        X_feat = df.loc[:, feature_cols].to_numpy()\n",
    "        n = len(df)\n",
    "        X = np.hstack([np.ones((n, 1)), X_feat])\n",
    "\n",
    "        if bws is None:\n",
    "            bw_selector = Sel_BW(\n",
    "                coords, y, X,\n",
    "                multi=multi, fixed=fixed,\n",
    "                kernel=kernel, spherical=spherical,\n",
    "                constant=False\n",
    "            )\n",
    "            _bws = bw_selector.search()\n",
    "        else:\n",
    "            _bws = bws\n",
    "\n",
    "        model = MGWR(\n",
    "            coords, y, X, bw_selector,\n",
    "            fixed=fixed, kernel=kernel, spherical=spherical,\n",
    "            constant=False\n",
    "        )\n",
    "        res = model.fit()\n",
    "        params = res.params  # (n, p+1): [b, a1, a2, ...]\n",
    "\n",
    "        df_out = df.copy()\n",
    "        df_out[\"b_result\"]  = params[:, 0]\n",
    "        df_out[\"a1_result\"] = params[:, 1]  \n",
    "        df_out[\"a2_result\"] = params[:, 2]  \n",
    "\n",
    "        stem = os.path.splitext(fname)[0]\n",
    "        out_path = os.path.join(out_dir, f\"{stem}_MGWR_result.txt\")\n",
    "        df_out.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "        results[fname] = df_out\n",
    "        print(f\"[OK] {out_path}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da6d29a1-6f9f-4814-ad3b-23d2dc2fdea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\".../Data_gen\"\n",
    "out_dir = r\".../Data_result/MGWR\"\n",
    "files = [\n",
    "    \"df_con_uni.txt\",\n",
    "    \"df_discon_uni.txt\",\n",
    "    \"df_multi_uni.txt\",\n",
    "    \"df_vor_uni.txt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d41f5829-73e9-4600-9ee2-19bd57960291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a159523b2f04b36af0f181cf35f427d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9705dd3ca85646b194f12e008cec23b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_gen\\..\\Data_result\\MGWR\\df_con_uni_MGWR_result.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de8c1c90463472994bf13f7f07cf004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f039f74119d74ca7ab8d066b64b95fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_gen\\..\\Data_result\\MGWR\\df_discon_uni_MGWR_result.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d29fd22ede4758b018f193e4b2234f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8672fca98f1249b99eb41840bc2495a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_gen\\..\\Data_result\\MGWR\\df_multi_uni_MGWR_result.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4b0e976244414fa826b024eefc2173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e0a96c127e414c917b0a400e32d452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_gen\\..\\Data_result\\MGWR\\df_vor_uni_MGWR_result.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'df_con_uni.txt':        u   v  spatial_x  spatial_y   a1_list   a2_list  b_list     feat1  \\\n",
       " 0      0   0   0.000000        0.0 -0.886420 -0.625670       3  1.643736   \n",
       " 1      1   0   0.204082        0.0 -0.880833 -0.645478       3 -0.366729   \n",
       " 2      2   0   0.408163        0.0 -0.862968 -0.665857       3  2.151588   \n",
       " 3      3   0   0.612245        0.0 -0.834523 -0.686958       3  1.184208   \n",
       " 4      4   0   0.816327        0.0 -0.797362 -0.708920       3 -2.434936   \n",
       " ...   ..  ..        ...        ...       ...       ...     ...       ...   \n",
       " 2495  45  49   9.183673       10.0  1.457911 -0.333272       3  0.132849   \n",
       " 2496  46  49   9.387755       10.0  1.460655 -0.351329       3  0.313519   \n",
       " 2497  47  49   9.591837       10.0  1.441659 -0.363042       3 -1.729553   \n",
       " 2498  48  49   9.795918       10.0  1.400341 -0.368267       3  1.916705   \n",
       " 2499  49  49  10.000000       10.0  1.336925 -0.366932       3 -0.008400   \n",
       " \n",
       "          feat2         y  b_result  a1_result  a2_result  \n",
       " 0    -2.796733  3.627980  2.964436  -1.172161  -0.351396  \n",
       " 1     1.098090  1.470252  2.964403  -1.142338  -0.370234  \n",
       " 2     2.702978  0.168949  2.964365  -1.117647  -0.393920  \n",
       " 3     1.974903  1.689696  2.964323  -1.097279  -0.416669  \n",
       " 4    -1.336811  3.743079  2.964275  -1.073136  -0.445485  \n",
       " ...        ...       ...       ...        ...        ...  \n",
       " 2495 -1.658735  6.178196  2.946096   1.776490  -0.257672  \n",
       " 2496 -1.989662  4.022676  2.946051   1.817381  -0.274954  \n",
       " 2497 -0.173105 -1.842380  2.946005   1.847731  -0.293998  \n",
       " 2498 -0.880873  5.405557  2.945958   1.871987  -0.307220  \n",
       " 2499  0.691380  4.090143  2.945911   1.891966  -0.321975  \n",
       " \n",
       " [2500 rows x 13 columns],\n",
       " 'df_discon_uni.txt':        u   v  spatial_x  spatial_y  a1_list  a2_list  b_list     feat1  \\\n",
       " 0      0   0   0.000000        0.0     -1.0     -2.0       3  1.643736   \n",
       " 1      1   0   0.204082        0.0     -1.0     -2.0       3 -0.366729   \n",
       " 2      2   0   0.408163        0.0     -1.0     -2.0       3  2.151588   \n",
       " 3      3   0   0.612245        0.0     -1.0     -2.0       3  1.184208   \n",
       " 4      4   0   0.816327        0.0     -1.0     -2.0       3 -2.434936   \n",
       " ...   ..  ..        ...        ...      ...      ...     ...       ...   \n",
       " 2495  45  49   9.183673       10.0      2.0      1.0       3  0.132849   \n",
       " 2496  46  49   9.387755       10.0      2.0      1.0       3  0.313519   \n",
       " 2497  47  49   9.591837       10.0      2.0      1.0       3 -1.729553   \n",
       " 2498  48  49   9.795918       10.0      2.0      1.0       3  1.916705   \n",
       " 2499  49  49  10.000000       10.0      2.0      1.0       3 -0.008400   \n",
       " \n",
       "          feat2          y  b_result  a1_result  a2_result  \n",
       " 0    -2.796733   8.028230  2.963351  -1.837473  -1.628567  \n",
       " 1     1.098090   1.655931  2.965140  -1.791257  -1.637257  \n",
       " 2     2.702978  -2.590639  2.966583  -1.718041  -1.624004  \n",
       " 3     1.974903  -1.189330  2.968751  -1.643703  -1.618311  \n",
       " 4    -1.336811  10.483122  2.971666  -1.513393  -1.577104  \n",
       " ...        ...        ...       ...        ...        ...  \n",
       " 2495 -1.658735   3.708045  2.829596   1.965553   0.876230  \n",
       " 2496 -1.989662   0.968027  2.829383   1.923153   0.930563  \n",
       " 2497 -0.173105   0.890116  2.829899   1.874129   0.880115  \n",
       " 2498 -0.880873   6.049530  2.831077   1.867351   0.824416  \n",
       " 2499  0.691380   1.933753  2.831077   1.853390   0.712884  \n",
       " \n",
       " [2500 rows x 13 columns],\n",
       " 'df_multi_uni.txt':        u   v  spatial_x  spatial_y  a1_list  a2_list  b_list     feat1  \\\n",
       " 0      0   0   0.000000        0.0     -1.0     -1.0       3  1.643736   \n",
       " 1      1   0   0.204082        0.0     -1.0     -1.0       3 -0.366729   \n",
       " 2      2   0   0.408163        0.0     -1.0     -1.0       3  2.151588   \n",
       " 3      3   0   0.612245        0.0     -1.0     -1.0       3  1.184208   \n",
       " 4      4   0   0.816327        0.0     -1.0     -1.0       3 -2.434936   \n",
       " ...   ..  ..        ...        ...      ...      ...     ...       ...   \n",
       " 2495  45  49   9.183673       10.0      2.0     -1.0       3  0.132849   \n",
       " 2496  46  49   9.387755       10.0      2.0     -1.0       3  0.313519   \n",
       " 2497  47  49   9.591837       10.0      2.0     -1.0       3 -1.729553   \n",
       " 2498  48  49   9.795918       10.0      2.0     -1.0       3  1.916705   \n",
       " 2499  49  49  10.000000       10.0      2.0     -1.0       3 -0.008400   \n",
       " \n",
       "          feat2         y  b_result  a1_result  a2_result  \n",
       " 0    -2.796733  3.727376  3.080638  -1.837938  -0.909859  \n",
       " 1     1.098090  1.774488  3.080824  -1.821997  -0.919193  \n",
       " 2     2.702978 -3.004054  3.081013  -1.800186  -0.924032  \n",
       " 3     1.974903  0.547886  3.081204  -1.762597  -0.930561  \n",
       " 4    -1.336811  7.158913  3.081397  -1.700701  -0.936846  \n",
       " ...        ...       ...       ...        ...        ...  \n",
       " 2495 -1.658735  7.413763  3.028426   2.003442  -0.967708  \n",
       " 2496 -1.989662  5.170274  3.028760   2.048577  -0.958103  \n",
       " 2497 -0.173105  0.076796  3.029087   2.074473  -0.942129  \n",
       " 2498 -0.880873  6.867013  3.029406   2.103490  -0.929074  \n",
       " 2499  0.691380 -0.662589  3.029719   2.119549  -0.923805  \n",
       " \n",
       " [2500 rows x 13 columns],\n",
       " 'df_vor_uni.txt':        u   v  spatial_x  spatial_y  a1_list  a2_list  b_list     feat1  \\\n",
       " 0      0   0   0.000000        0.0     -3.0      2.0     3.0  1.643736   \n",
       " 1      1   0   0.204082        0.0     -3.0      2.0     3.0 -0.366729   \n",
       " 2      2   0   0.408163        0.0     -3.0      2.0     3.0  2.151588   \n",
       " 3      3   0   0.612245        0.0     -3.0      2.0     3.0  1.184208   \n",
       " 4      4   0   0.816327        0.0     -3.0      2.0     3.0 -2.434936   \n",
       " ...   ..  ..        ...        ...      ...      ...     ...       ...   \n",
       " 2495  45  49   9.183673       10.0      3.0     -2.0     3.0  0.132849   \n",
       " 2496  46  49   9.387755       10.0      3.0     -2.0     3.0  0.313519   \n",
       " 2497  47  49   9.591837       10.0      3.0     -2.0     3.0 -1.729553   \n",
       " 2498  48  49   9.795918       10.0      3.0     -2.0     3.0  1.916705   \n",
       " 2499  49  49  10.000000       10.0      3.0     -2.0     3.0 -0.008400   \n",
       " \n",
       "          feat2          y  b_result  a1_result  a2_result  \n",
       " 0    -2.796733  -5.546030  2.922449  -2.999664   2.054429  \n",
       " 1     1.098090   8.046399  2.922562  -3.021268   2.064247  \n",
       " 2     2.702978   2.099762  2.922683  -3.060904   2.084158  \n",
       " 3     1.974903   5.933474  2.922814  -3.105648   2.118978  \n",
       " 4    -1.336811   8.683081  2.922956  -3.213979   2.145368  \n",
       " ...        ...        ...       ...        ...        ...  \n",
       " 2495 -1.658735   8.784720  2.919824   2.701626  -2.910789  \n",
       " 2496 -1.989662  11.343706  2.920160   2.302129  -3.223623  \n",
       " 2497 -0.173105  -1.035159  2.920487   1.631613  -3.365003  \n",
       " 2498 -0.880873  12.548693  2.920804   1.143496  -3.501909  \n",
       " 2499  0.691380   0.901004  2.921113   0.756766  -3.519019  \n",
       " \n",
       " [2500 rows x 13 columns]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_mgwr(\n",
    "    data_dir=data_dir,\n",
    "    file_names=files,\n",
    "    feature_cols=[\"feat1\", \"feat2\"],\n",
    "    y_col=\"y\",\n",
    "    coord_cols=(\"spatial_x\", \"spatial_y\"),\n",
    "    output_dir=os.path.join(data_dir, \"..\", \"Data_result\", \"MGWR\"),\n",
    "    multi=True,\n",
    "    fixed=False,\n",
    "    kernel=\"bisquare\",\n",
    "    spherical=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ca926-914d-4aa5-93d9-e6778ea9b203",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe86f7-ea5e-43e0-abe8-c67f53571d5a",
   "metadata": {},
   "source": [
    "## KM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a57c306a-54b8-4180-8ee4-0f25c74bcbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bic_r2 (Xarr, Yarr, labels, rcoeff, per_region_sigma=True):\n",
    "    \n",
    "    N, p = Xarr.shape\n",
    "    lab = np.asarray(labels)\n",
    "\n",
    "    beta_mat = np.vstack([rcoeff[int(lb)] for lb in lab])  # (N,p) [b,a1,a2,...]\n",
    "    yhat = np.sum(Xarr * beta_mat, axis=1)\n",
    "    resid = Yarr - yhat\n",
    "\n",
    "    SSE = float(np.sum(resid ** 2))\n",
    "    SST = np.sum((Yarr - Yarr.mean())**2)\n",
    "\n",
    "    R = len(np.unique(lab))\n",
    "    k = R * p\n",
    "\n",
    "    BIC = N * np.log(SSE / N) + k * np.log(N)\n",
    "    R_2 = 1 - SSE/SST\n",
    "\n",
    "    return BIC, R_2, k, SSE/2500\n",
    "\n",
    "\n",
    "def run_kmodels_bic(\n",
    "    data_dir, file_names,\n",
    "    n_regions=5, micro_clusters=None, min_region=20,\n",
    "    save_region_label=False, verbose=True, output_dir=None,\n",
    "    R_min: int = 2, R_max: int = 15, per_region_sigma: bool = True\n",
    "):\n",
    "\n",
    "    R_min = int(R_min); R_max = int(R_max)\n",
    "    if R_min < 1: R_min = 1\n",
    "    if R_max < R_min: R_min, R_max = R_max, R_min\n",
    "\n",
    "    files = [file_names] if isinstance(file_names, str) else list(file_names)\n",
    "    out = {}\n",
    "\n",
    "    for fname in files:\n",
    "        df = pd.read_csv(os.path.join(data_dir, fname), sep=\"\\t\")\n",
    "\n",
    "        X = df[[\"feat1\", \"feat2\"]].to_numpy()\n",
    "        y = df[\"y\"].to_numpy()\n",
    "        # Xs = preprocessing.StandardScaler().fit_transform(X)\n",
    "        # ys = preprocessing.StandardScaler().fit_transform(y.reshape(-1, 1)).ravel()\n",
    "        Xarr = np.hstack([np.ones((len(y), 1)), X])\n",
    "        Yarr = y\n",
    "        side_x = int(df[\"u\"].max()) + 1\n",
    "        side_y = int(df[\"v\"].max()) + 1\n",
    "        assert side_x * side_y == len(df),\n",
    "        w = weights.lat2W(side_y, side_x).symmetrize()\n",
    "\n",
    "        rows = []\n",
    "        for R in range(R_min, R_max + 1):\n",
    "            try:\n",
    "                K_micro = 2 * R\n",
    "                clabel, _ = kmodels(Xarr, Yarr, K_micro, w,\n",
    "                                    init_stoc_step=False, verbose=False)\n",
    "                slabel = split_components(w, clabel)\n",
    "\n",
    "                rlabel, rcoeff, _ = greedy_merge(\n",
    "                    Xarr, Yarr, R, w, slabel, min_size=min_region, verbose=False\n",
    "                )\n",
    "                bic, r_2, k, MSE = get_bic_r2(Xarr, Yarr, rlabel, rcoeff)\n",
    "                \n",
    "                rows.append({\"n_regions\": R, \"BIC\": bic, \"R2\": r_2, \"MSE\": MSE})\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"{fname} | n_regions={R:2d} (K_micro={K_micro:2d})  BIC={bic:.6f} R2={r_2:.6f} MSE={MSE:.6f} \")\n",
    "            except Exception as e:\n",
    "                rows.append({\"n_regions\": R, \"BIC\": np.nan})\n",
    "                if verbose:\n",
    "                    print(f\"{fname} | n_regions={R:2d} (K_micro={2*R:2d})  FAILED → {e}\")\n",
    "\n",
    "        out[fname] = pd.DataFrame(rows)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "072fb505-e789-4b75-90bc-cc1f39da27ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_con_uni.txt | n_regions= 2 (K_micro= 4)  BIC=4087.653847 R2=0.428319 MSE=5.034347 \n",
      "df_con_uni.txt | n_regions= 3 (K_micro= 6)  BIC=2919.723785 R2=0.645035 MSE=3.125902 \n",
      "df_con_uni.txt | n_regions= 4 (K_micro= 8)  BIC=2469.867122 R2=0.706262 MSE=2.586722 \n",
      "df_con_uni.txt | n_regions= 5 (K_micro=10)  BIC=2174.554217 R2=0.741428 MSE=2.277042 \n",
      "df_con_uni.txt | n_regions= 6 (K_micro=12)  BIC=1885.145209 R2=0.771846 MSE=2.009177 \n",
      "df_con_uni.txt | n_regions= 7 (K_micro=14)  BIC=1552.410804 R2=0.802144 MSE=1.742363 \n",
      "df_con_uni.txt | n_regions= 8 (K_micro=16)  BIC=1578.210125 R2=0.801960 MSE=1.743986 \n",
      "df_con_uni.txt | n_regions= 9 (K_micro=18)  BIC=1442.540713 R2=0.814173 MSE=1.636429 \n",
      "df_con_uni.txt | n_regions=10 (K_micro=20)  BIC=1206.069237 R2=0.832525 MSE=1.474825 \n",
      "df_con_uni.txt | n_regions=11 (K_micro=22)  BIC=1306.122473 R2=0.827315 MSE=1.520701 \n",
      "df_con_uni.txt | n_regions=12 (K_micro=24)  BIC=1158.150577 R2=0.838760 MSE=1.419911 \n",
      "df_con_uni.txt | n_regions=13 (K_micro=26)  BIC=1113.707161 R2=0.843082 MSE=1.381856 \n",
      "df_con_uni.txt | n_regions=14 (K_micro=28)  BIC=1129.047260 R2=0.843591 MSE=1.377369 \n",
      "df_con_uni.txt | n_regions=15 (K_micro=30)  BIC=1052.947064 R2=0.849699 MSE=1.323588 \n",
      "df_discon_uni.txt | n_regions= 2 (K_micro= 4)  BIC=6762.410336 R2=0.446412 MSE=14.675603 \n",
      "df_discon_uni.txt | n_regions= 3 (K_micro= 6)  BIC=5965.519353 R2=0.601273 MSE=10.570226 \n",
      "df_discon_uni.txt | n_regions= 4 (K_micro= 8)  BIC=5107.586538 R2=0.719741 MSE=7.429653 \n",
      "df_discon_uni.txt | n_regions= 5 (K_micro=10)  BIC=4557.203782 R2=0.777223 MSE=5.905814 \n",
      "df_discon_uni.txt | n_regions= 6 (K_micro=12)  BIC=4450.312045 R2=0.788542 MSE=5.605743 \n",
      "df_discon_uni.txt | n_regions= 7 (K_micro=14)  BIC=4152.890733 R2=0.814014 MSE=4.930470 \n",
      "df_discon_uni.txt | n_regions= 8 (K_micro=16)  BIC=4456.846321 R2=0.791932 MSE=5.515861 \n",
      "df_discon_uni.txt | n_regions= 9 (K_micro=18)  BIC=4043.234089 R2=0.825307 MSE=4.631098 \n",
      "df_discon_uni.txt | n_regions=10 (K_micro=20)  BIC=4053.648951 R2=0.826217 MSE=4.606973 \n",
      "df_discon_uni.txt | n_regions=11 (K_micro=22)  BIC=4219.957354 R2=0.815999 MSE=4.877855 \n",
      "df_discon_uni.txt | n_regions=12 (K_micro=24)  BIC=4195.757887 R2=0.819475 MSE=4.785722 \n",
      "df_discon_uni.txt | n_regions=13 (K_micro=26)  BIC=4151.321071 R2=0.824312 MSE=4.657474 \n",
      "df_discon_uni.txt | n_regions=14 (K_micro=28)  BIC=4287.243542 R2=0.816229 MSE=4.871751 \n",
      "df_discon_uni.txt | n_regions=15 (K_micro=30)  BIC=4227.497023 R2=0.822246 MSE=4.712252 \n",
      "df_multi_uni.txt | n_regions= 2 (K_micro= 4)  BIC=6073.357999 R2=0.416021 MSE=11.140259 \n",
      "df_multi_uni.txt | n_regions= 3 (K_micro= 6)  BIC=4849.197098 R2=0.645464 MSE=6.763309 \n",
      "df_multi_uni.txt | n_regions= 4 (K_micro= 8)  BIC=4369.192154 R2=0.710134 MSE=5.529633 \n",
      "df_multi_uni.txt | n_regions= 5 (K_micro=10)  BIC=4227.420737 R2=0.728674 MSE=5.175956 \n",
      "df_multi_uni.txt | n_regions= 6 (K_micro=12)  BIC=3811.487821 R2=0.772407 MSE=4.341683 \n",
      "df_multi_uni.txt | n_regions= 7 (K_micro=14)  BIC=3810.860454 R2=0.774590 MSE=4.300031 \n",
      "df_multi_uni.txt | n_regions= 8 (K_micro=16)  BIC=3540.706252 R2=0.799569 MSE=3.823521 \n",
      "df_multi_uni.txt | n_regions= 9 (K_micro=18)  BIC=3520.339682 R2=0.803053 MSE=3.757058 \n",
      "df_multi_uni.txt | n_regions=10 (K_micro=20)  BIC=3454.405893 R2=0.809972 MSE=3.625071 \n",
      "df_multi_uni.txt | n_regions=11 (K_micro=22)  BIC=3483.108073 R2=0.809574 MSE=3.632662 \n",
      "df_multi_uni.txt | n_regions=12 (K_micro=24)  BIC=3437.882865 R2=0.814735 MSE=3.534200 \n",
      "df_multi_uni.txt | n_regions=13 (K_micro=26)  BIC=3388.361051 R2=0.820066 MSE=3.432502 \n",
      "df_multi_uni.txt | n_regions=14 (K_micro=28)  BIC=3270.674022 R2=0.829945 MSE=3.244060 \n",
      "df_multi_uni.txt | n_regions=15 (K_micro=30)  BIC=3371.473233 R2=0.824602 MSE=3.345969 \n",
      "df_vor_uni.txt | n_regions= 2 (K_micro= 4)  BIC=7125.881999 R2=0.528201 MSE=16.972172 \n",
      "df_vor_uni.txt | n_regions= 3 (K_micro= 6)  BIC=5935.963525 R2=0.709618 MSE=10.445997 \n",
      "df_vor_uni.txt | n_regions= 4 (K_micro= 8)  BIC=5379.484278 R2=0.769738 MSE=8.283274 \n",
      "df_vor_uni.txt | n_regions= 5 (K_micro=10)  BIC=4354.253965 R2=0.848629 MSE=5.445324 \n",
      "df_vor_uni.txt | n_regions= 6 (K_micro=12)  BIC=4413.091333 R2=0.846472 MSE=5.522902 \n",
      "df_vor_uni.txt | n_regions= 7 (K_micro=14)  BIC=4436.046286 R2=0.846504 MSE=5.521759 \n",
      "df_vor_uni.txt | n_regions= 8 (K_micro=16)  BIC=4477.285715 R2=0.845409 MSE=5.561142 \n",
      "df_vor_uni.txt | n_regions= 9 (K_micro=18)  BIC=4568.604974 R2=0.841156 MSE=5.714131 \n",
      "df_vor_uni.txt | n_regions=10 (K_micro=20)  BIC=4463.720265 R2=0.849106 MSE=5.428156 \n",
      "df_vor_uni.txt | n_regions=11 (K_micro=22)  BIC=4722.615184 R2=0.834206 MSE=5.964163 \n",
      "df_vor_uni.txt | n_regions=12 (K_micro=24)  BIC=4570.225437 R2=0.845468 MSE=5.559032 \n",
      "df_vor_uni.txt | n_regions=13 (K_micro=26)  BIC=4460.794662 R2=0.853468 MSE=5.271225 \n",
      "df_vor_uni.txt | n_regions=14 (K_micro=28)  BIC=4572.879037 R2=0.848182 MSE=5.461414 \n",
      "df_vor_uni.txt | n_regions=15 (K_micro=30)  BIC=4585.837371 R2=0.848819 MSE=5.438494 \n"
     ]
    }
   ],
   "source": [
    "data_dir   = r\"D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_gen\"\n",
    "files = [\n",
    "    \"df_con_uni.txt\",\n",
    "    \"df_discon_uni.txt\",\n",
    "    \"df_multi_uni.txt\",\n",
    "    \"df_vor_uni.txt\"\n",
    "]\n",
    "\n",
    "\n",
    "bic_km_2 = run_kmodels_bic(\n",
    "    data_dir, files,\n",
    "    min_region=20,\n",
    "    R_min=2, R_max=15,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a96be56-939d-4994-a989-46cfc1737503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_bic(\n",
    "    bic_dict: dict,\n",
    "    out_path: str | None = None,\n",
    "    split_dir: str | None = None,\n",
    "    *,\n",
    "    dropna: bool = False,\n",
    "    ensure_int_regions: bool = True,\n",
    "    drop_file_col_when_split: bool = True\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    rows = []\n",
    "    for fname, df in bic_dict.items():\n",
    "        df2 = df.copy()\n",
    "        df2.insert(0, \"file\", fname)\n",
    "        rows.append(df2)\n",
    "\n",
    "    big = pd.concat(rows, ignore_index=True)\n",
    "    required = {\"file\", \"n_regions\", \"BIC\"}\n",
    "    if ensure_int_regions:\n",
    "        big[\"n_regions\"] = big[\"n_regions\"].astype(\"Int64\").astype(\"float\").astype(int)\n",
    "    if dropna:\n",
    "        big = big.dropna(subset=[\"BIC\"])\n",
    "    big = big.sort_values([\"file\", \"n_regions\"], kind=\"mergesort\")\n",
    "    if out_path:\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        big.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    if split_dir:\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "        for f, sub in big.groupby(\"file\", sort=True):\n",
    "            sub_out = sub if not drop_file_col_when_split else sub[[\"n_regions\", \"BIC\", \"R2\", \"MSE\"]]\n",
    "            out_file = os.path.join(split_dir, f)\n",
    "            os.makedirs(os.path.dirname(out_file), exist_ok=True)\n",
    "            sub_out.to_csv(out_file, sep=\"\\t\", index=False)\n",
    "            print(f\"[OK]：{out_file}\")\n",
    "    return big"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c40a2a-b7c0-4a1b-a886-d4eaccb6d25c",
   "metadata": {},
   "source": [
    "## SKEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a9848e0-584c-40fd-a64a-6ab3d28d5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bic_r2_sk (labels, X_feat, y):\n",
    "\n",
    "    labels = np.asarray(labels)\n",
    "    uniq = np.unique(labels)\n",
    "    X = np.asarray(X_feat, float)\n",
    "    y = np.asarray(y, float).ravel()\n",
    "\n",
    "    N, p0 = X_feat.shape\n",
    "    P = p0 + 1\n",
    "\n",
    "    SSE = 0.0\n",
    "    for r in uniq:\n",
    "        idx = (labels == r)\n",
    "        Xr = X_feat[idx, :]\n",
    "        yr = y[idx]\n",
    "        Xrd = np.c_[np.ones(len(yr)), Xr]\n",
    "        beta, *_ = np.linalg.lstsq(Xrd, yr, rcond=None)\n",
    "        SSE += float(np.sum((yr - Xrd @ beta) ** 2))\n",
    "\n",
    "    y_center = y - y.mean()\n",
    "    SST = np.sum((y - y.mean())**2)\n",
    "    r2 = 1.0 - SSE / SST\n",
    "\n",
    "    R = len(uniq)\n",
    "    k = R * P\n",
    "    bic = N * np.log(SSE / N) + k * np.log(N)\n",
    "    return bic, r2, SSE/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82f369ec-9c22-4c4e-af17-db363fe01b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_skater_global_bic_singlefit(\n",
    "    data_dir: str,\n",
    "    file_names,\n",
    "    *,\n",
    "    R_min: int = 2,\n",
    "    R_max: int = 15,\n",
    "    quorum: int = 20,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    files = [file_names] if isinstance(file_names, str) else list(file_names)\n",
    "    out = {}\n",
    "\n",
    "    for fname in files:\n",
    "        path = os.path.join(data_dir, fname)\n",
    "        df = pd.read_csv(path, sep=\"\\t\")\n",
    "        # X, y\n",
    "        X = df[[\"feat1\", \"feat2\"]].to_numpy()\n",
    "        y = df[\"y\"].to_numpy()\n",
    "        side_x = int(df[\"u\"].max()) + 1\n",
    "        side_y = int(df[\"v\"].max()) + 1\n",
    "        w = weights.lat2W(side_y, side_x).symmetrize()\n",
    "        X_std = StandardScaler().fit_transform(X)\n",
    "        rows = []\n",
    "        try:\n",
    "            skater = Skater_reg()\n",
    "            res = skater.fit(\n",
    "                R_max, w, X_std,\n",
    "                {\"reg\": spreg.OLS, \"y\": y, \"x\": X},\n",
    "                quorum=quorum\n",
    "            )\n",
    "            keep = {}\n",
    "            for rec in res._trace:\n",
    "                labels = np.asarray(rec[0]).astype(int)\n",
    "                K = np.unique(labels).size\n",
    "                if R_min <= K <= R_max:\n",
    "                    keep[K] = labels\n",
    "            for K in sorted(keep):\n",
    "                bic, r2, MSE = get_bic_r2_sk(keep[K], X, y)\n",
    "                rows.append({\"n_regions\": K, \"BIC\": bic, \"R2\": r2, \"MSE\": MSE})\n",
    "                if verbose:\n",
    "                    print(f\"{fname} | K={K:2d}  BIC={bic:.6f}  R2={r2:.6f}  MSE={MSE:.6f}\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"{fname} | single fit FAILED → {e}\")\n",
    "        out[fname] = pd.DataFrame(rows).sort_values(\"n_regions\").reset_index(drop=True)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b3f6fca-c24e-4d9b-8556-fba8860b93f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_con_uni.txt | K= 2  BIC=4601.167752  R2=0.297963  MSE=6.182294\n",
      "df_con_uni.txt | K= 3  BIC=3780.140258  R2=0.499210  MSE=4.410065\n",
      "df_con_uni.txt | K= 4  BIC=2888.658027  R2=0.652694  MSE=3.058449\n",
      "df_con_uni.txt | K= 5  BIC=2703.448766  R2=0.680508  MSE=2.813517\n",
      "df_con_uni.txt | K= 6  BIC=2509.216714  R2=0.707153  MSE=2.578876\n",
      "df_con_uni.txt | K= 7  BIC=2334.028685  R2=0.729523  MSE=2.381879\n",
      "df_con_uni.txt | K= 8  BIC=2235.056594  R2=0.742451  MSE=2.268030\n",
      "df_con_uni.txt | K= 9  BIC=2130.140492  R2=0.755344  MSE=2.154495\n",
      "df_con_uni.txt | K=10  BIC=2059.162106  R2=0.764415  MSE=2.074616\n",
      "df_con_uni.txt | K=11  BIC=1998.038543  R2=0.772253  MSE=2.005589\n",
      "df_con_uni.txt | K=12  BIC=1941.140613  R2=0.779458  MSE=1.942139\n",
      "df_con_uni.txt | K=13  BIC=1898.800280  R2=0.785188  MSE=1.891679\n",
      "df_con_uni.txt | K=14  BIC=1862.116301  R2=0.790295  MSE=1.846704\n",
      "df_con_uni.txt | K=15  BIC=1828.503777  R2=0.795030  MSE=1.805015\n",
      "df_discon_uni.txt | K= 2  BIC=7742.371081  R2=0.180737  MSE=21.718637\n",
      "df_discon_uni.txt | K= 3  BIC=7209.449544  R2=0.344205  MSE=17.385095\n",
      "df_discon_uni.txt | K= 4  BIC=7006.884258  R2=0.400897  MSE=15.882189\n",
      "df_discon_uni.txt | K= 5  BIC=6898.637085  R2=0.431645  MSE=15.067055\n",
      "df_discon_uni.txt | K= 6  BIC=6805.912884  R2=0.457457  MSE=14.382785\n",
      "df_discon_uni.txt | K= 7  BIC=6709.327378  R2=0.482896  MSE=13.708402\n",
      "df_discon_uni.txt | K= 8  BIC=6605.893249  R2=0.508490  MSE=13.029897\n",
      "df_discon_uni.txt | K= 9  BIC=6530.557091  R2=0.527538  MSE=12.524956\n",
      "df_discon_uni.txt | K=10  BIC=6359.061544  R2=0.562983  MSE=11.585289\n",
      "df_discon_uni.txt | K=11  BIC=6300.699965  R2=0.577057  MSE=11.212201\n",
      "df_discon_uni.txt | K=12  BIC=6254.348116  R2=0.588706  MSE=10.903382\n",
      "df_discon_uni.txt | K=13  BIC=6182.216268  R2=0.604138  MSE=10.494291\n",
      "df_discon_uni.txt | K=14  BIC=6160.010216  R2=0.611305  MSE=10.304288\n",
      "df_discon_uni.txt | K=15  BIC=6139.598765  R2=0.618068  MSE=10.124991\n",
      "df_multi_uni.txt | K= 2  BIC=6604.325050  R2=0.277837  MSE=13.776336\n",
      "df_multi_uni.txt | K= 3  BIC=5989.748054  R2=0.440507  MSE=10.673165\n",
      "df_multi_uni.txt | K= 4  BIC=5156.873806  R2=0.602779  MSE=7.577582\n",
      "df_multi_uni.txt | K= 5  BIC=4863.186709  R2=0.650106  MSE=6.674741\n",
      "df_multi_uni.txt | K= 6  BIC=4755.954802  R2=0.667929  MSE=6.334740\n",
      "df_multi_uni.txt | K= 7  BIC=4659.175251  R2=0.683524  MSE=6.037247\n",
      "df_multi_uni.txt | K= 8  BIC=4557.105987  R2=0.699024  MSE=5.741563\n",
      "df_multi_uni.txt | K= 9  BIC=4505.293947  R2=0.707952  MSE=5.571241\n",
      "df_multi_uni.txt | K=10  BIC=4455.817451  R2=0.716351  MSE=5.411024\n",
      "df_multi_uni.txt | K=11  BIC=4384.477043  R2=0.726907  MSE=5.209654\n",
      "df_multi_uni.txt | K=12  BIC=4335.765091  R2=0.734680  MSE=5.061383\n",
      "df_multi_uni.txt | K=13  BIC=4273.202573  R2=0.743655  MSE=4.890164\n",
      "df_multi_uni.txt | K=14  BIC=4220.004230  R2=0.751397  MSE=4.742468\n",
      "df_multi_uni.txt | K=15  BIC=4178.868746  R2=0.757740  MSE=4.621478\n",
      "df_vor_uni.txt | K= 2  BIC=7594.056650  R2=0.431033  MSE=20.467637\n",
      "df_vor_uni.txt | K= 3  BIC=7281.760948  R2=0.502540  MSE=17.895295\n",
      "df_vor_uni.txt | K= 4  BIC=7053.163655  R2=0.550252  MSE=16.178934\n",
      "df_vor_uni.txt | K= 5  BIC=6881.075090  R2=0.584092  MSE=14.961583\n",
      "df_vor_uni.txt | K= 6  BIC=6693.528322  R2=0.617757  MSE=13.750541\n",
      "df_vor_uni.txt | K= 7  BIC=6604.362446  R2=0.634597  MSE=13.144757\n",
      "df_vor_uni.txt | K= 8  BIC=6501.778443  R2=0.652565  MSE=12.498399\n",
      "df_vor_uni.txt | K= 9  BIC=6405.728378  R2=0.668784  MSE=11.914923\n",
      "df_vor_uni.txt | K=10  BIC=6314.493789  R2=0.683638  MSE=11.380586\n",
      "df_vor_uni.txt | K=11  BIC=6250.178410  R2=0.694554  MSE=10.987892\n",
      "df_vor_uni.txt | K=12  BIC=6190.074510  R2=0.704597  MSE=10.626635\n",
      "df_vor_uni.txt | K=13  BIC=6144.451968  R2=0.712649  MSE=10.336958\n",
      "df_vor_uni.txt | K=14  BIC=6067.926728  R2=0.723916  MSE=9.931651\n",
      "df_vor_uni.txt | K=15  BIC=6047.760432  R2=0.728693  MSE=9.759794\n"
     ]
    }
   ],
   "source": [
    "data_dir   = r\"D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_gen\"\n",
    "files = [\n",
    "    \"df_con_uni.txt\",\n",
    "    #\"df_con_grf.txt\",\n",
    "    \"df_discon_uni.txt\",\n",
    "    #\"df_discon_grf.txt\",\n",
    "    \"df_multi_uni.txt\",\n",
    "    #\"df_multi_grf.txt\",\n",
    "    #\"df_vor_grf.txt\",\n",
    "    \"df_vor_uni.txt\"\n",
    "]\n",
    "\n",
    "\n",
    "bic_sk = sweep_skater_global_bic_singlefit(\n",
    "    data_dir, files,\n",
    "    R_min=2, R_max=15,\n",
    "    quorum=20,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea09a7-086b-4bf4-9911-aaaa71956fad",
   "metadata": {},
   "source": [
    "## MGWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc47594-6501-4942-a892-ee7eee43f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mgwr_bic(\n",
    "    data_dir: str,\n",
    "    file_names: Sequence[str] | str,\n",
    "    *,\n",
    "    feature_cols: Sequence[str],                 \n",
    "    y_col: str = \"y\",\n",
    "    coord_cols: Tuple[str, str] = (\"spatial_x\", \"spatial_x\"),\n",
    "    output_dir: [str] = None,            \n",
    "    multi: bool = True,                          \n",
    "    fixed: bool = False,                         \n",
    "    kernel: str = \"bisquare\",                    \n",
    "    spherical: bool = False,                     \n",
    "    verbose: bool = True,\n",
    ") -> Tuple[[str, pd.DataFrame], pd.DataFrame]:\n",
    "\n",
    "    files = [file_names] if isinstance(file_names, str) else list(file_names)\n",
    "    out_dir = data_dir if output_dir is None else output_dir\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    results: Dict[str, pd.DataFrame] = {}\n",
    "    metrics_rows: List[dict] = []\n",
    "\n",
    "    for fname in files:\n",
    "        path = os.path.join(data_dir, fname)\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(path)\n",
    "        df = pd.read_csv(path, sep=\"\\t\")\n",
    "\n",
    "        coords  = df.loc[:, coord_cols].to_numpy()\n",
    "        y       = df.loc[:, y_col].to_numpy().reshape(-1, 1)\n",
    "        X  = df.loc[:, feature_cols].to_numpy()\n",
    "        n       = len(df)\n",
    "\n",
    "        # X = StandardScaler().fit_transform(X)\n",
    "        # y = StandardScaler().fit_transform(y.reshape(-1, 1))\n",
    "        \n",
    "        # constant=False\n",
    "        X = np.hstack([np.ones((n, 1)), X])\n",
    "\n",
    "        bw_selector = Sel_BW(\n",
    "            coords, y, X,\n",
    "            multi=multi,\n",
    "            constant=False\n",
    "        )\n",
    "\n",
    "        #kernel='bw_selector.search(criterion='BIC')\n",
    "        #selector.search()\n",
    "\n",
    "        bw_selector.search()\n",
    "\n",
    "        model = MGWR(\n",
    "            coords, y, X, bw_selector,\n",
    "            constant=False\n",
    "        )\n",
    "        res = model.fit()\n",
    "\n",
    "        params = res.params  \n",
    "        df_out = df.copy()\n",
    "        df_out[\"b_result\"]  = params[:, 0]\n",
    "        df_out[\"a1_result\"] = params[:, 1]\n",
    "        df_out[\"a2_result\"] = params[:, 2]\n",
    "\n",
    "        y_true = y.ravel()\n",
    "        yhat   = np.asarray(res.predy).ravel()\n",
    "        N      = y_true.size\n",
    "        SSE    = float(np.sum((y_true - yhat)**2))\n",
    "        SST    = float(np.sum((y_true - y_true.mean())**2))\n",
    "        R2     = np.nan if SST == 0.0 else (1.0 - SSE / SST)\n",
    "\n",
    "        BIC_enp = N * np.log(SSE / N) + enp * np.log(N)\n",
    "\n",
    "        AIC_mgwr  = float(res.aic)\n",
    "        AICc_mgwr = float(res.aicc)\n",
    "        BIC_mgwr  = float(res.bic)\n",
    "\n",
    "        stem = os.path.splitext(fname)[0]\n",
    "        out_coef = os.path.join(out_dir, f\"{stem}_MGWR_result.txt\")\n",
    "        df_out.to_csv(out_coef, sep=\"\\t\", index=False)\n",
    "\n",
    "        out_metrics = os.path.join(out_dir, f\"{stem}_MGWR_metrics.txt\")\n",
    "        pd.DataFrame([{\n",
    "            \"file\": fname,\n",
    "            \"N\": N,\n",
    "            \"ENP\": enp,\n",
    "            \"SSE\": SSE,\n",
    "            \"R2\": R2,\n",
    "            \"BIC_enp\": BIC_enp,\n",
    "            \"BIC_mgwr\": BIC_mgwr,\n",
    "            # \"AIC\": AIC_mgwr,\n",
    "            # \"AICc\": AICc_mgwr\n",
    "        }]).to_csv(out_metrics, sep=\"\\t\", index=False)\n",
    "\n",
    "        results[fname] = df_out\n",
    "        metrics_rows.append({\n",
    "            \"file\": fname,\n",
    "            \"N\": N,\n",
    "            \"ENP\": enp,\n",
    "            \"SSE\": SSE,\n",
    "            \"R2\": R2,\n",
    "            \"BIC_enp\": BIC_enp,\n",
    "            \"BIC_mgwr\": BIC_mgwr,\n",
    "            # \"AIC\": AIC_mgwr,\n",
    "            # \"AICc\": AICc_mgwr\n",
    "        })\n",
    "        if verbose:\n",
    "            print(f\"[OK] {out_coef} | BIC_enp={BIC_enp:.6f}, R2={R2:.6f}, ENP={enp:.2f}\")\n",
    "\n",
    "    return results, metrics_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6019b1f1-be00-4634-8517-ffc3efcefd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d93b6e5bf854f948f744a287a64050f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222c87ee7b56469db0fa0fc67d650e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR/uni\\df_con_uni_MGWR_result.txt | BIC_enp=1194.905771, R2=0.865970, ENP=99.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bb5ab7afe54172ad1acc4ac3cda6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663b114623f64138bf5204f3a4a8c75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR/uni\\df_discon_uni_MGWR_result.txt | BIC_enp=6248.563384, R2=0.824368, ENP=307.15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47eb8aa185744b69b0d2d7a4ec66bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208d7105935a41c7af744c755fe9ff4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR/uni\\df_multi_uni_MGWR_result.txt | BIC_enp=4266.129714, R2=0.841107, ENP=190.92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093cf723a923468492f2e1610abe0e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc4103ab7794f4dbedf337ced242129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR/uni\\df_vor_uni_MGWR_result.txt | BIC_enp=6524.289415, R2=0.848666, ENP=292.43\n"
     ]
    }
   ],
   "source": [
    "data_dir   = r\"D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_gen\"\n",
    "files = [\n",
    "    \"df_con_uni.txt\",\n",
    "    \"df_discon_uni.txt\",\n",
    "    \"df_multi_uni.txt\",\n",
    "    \"df_vor_uni.txt\"\n",
    "]\n",
    "\n",
    "coef_dict, metrics_df = run_mgwr_bic(\n",
    "    data_dir=data_dir,\n",
    "    file_names=files,\n",
    "    feature_cols=[\"feat1\",\"feat2\"],\n",
    "    y_col=\"y\",\n",
    "    coord_cols=(\"spatial_x\",\"spatial_y\"),\n",
    "    output_dir=r\"D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR/uni\",\n",
    "    fixed=False, kernel=\"bisquare\", spherical=False,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "51bd2978-abc9-4480-a7ea-a1ae7905fe0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec05372fc694ef9bbc8f68eca9ed462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44c37578b0f47c3807314755f49135d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR\\df_con_uni_MGWR_result.txt | BIC_enp=1194.905771, R2=0.865970, ENP=99.76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13804c462aa147f39eea192b33a75e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582e1d3cad6d4cc69afdc6b36d77811a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR\\df_con_grf_MGWR_result.txt | BIC_enp=-1382.094827, R2=0.856127, ENP=83.29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7dbf8832f2648f9a5c161828815720b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2882986da3bd427793d471e8709a2482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04972605567248ab8d301dddadc7ba8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR\\df_discon_grf_MGWR_result.txt | BIC_enp=2870.630761, R2=0.833186, ENP=213.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d28291bd4904b57a9a5e7599e0cf398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e592934f34a3407aa9e2b3fce8ddc529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR\\df_multi_uni_MGWR_result.txt | BIC_enp=4266.129714, R2=0.841107, ENP=190.92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d0d22afaf74612ab125cd22aa45724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5074ac7a369943deb50098a35c111249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR\\df_multi_grf_MGWR_result.txt | BIC_enp=962.274003, R2=0.836691, ENP=148.22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4c2caecc1b405c99a04bc0a5d7f863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc80ca392b44e0e8cc59441a2276f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR\\df_vor_grf_MGWR_result.txt | BIC_enp=3439.147994, R2=0.819714, ENP=227.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cad623d85a48baa17745ea035ad448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Backfitting:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f22b3bc8fd148e9bb117a064ee753f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR\\df_vor_uni_MGWR_result.txt | BIC_enp=6524.289415, R2=0.848666, ENP=292.43\n"
     ]
    }
   ],
   "source": [
    "data_dir   = r\"D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_gen\"\n",
    "files = [\n",
    "    \"df_con_uni.txt\",\n",
    "    \"df_con_grf.txt\",\n",
    "    \"df_discon_uni.txt\",\n",
    "    \"df_discon_grf.txt\",\n",
    "    \"df_multi_uni.txt\",\n",
    "    \"df_multi_grf.txt\",\n",
    "    \"df_vor_grf.txt\",\n",
    "    \"df_vor_uni.txt\"\n",
    "]\n",
    "\n",
    "coef_dict, metrics_df = run_mgwr_bic(\n",
    "    data_dir=data_dir,\n",
    "    file_names=files,\n",
    "    feature_cols=[\"feat1\",\"feat2\"],\n",
    "    y_col=\"y\",\n",
    "    coord_cols=(\"spatial_x\",\"spatial_y\"),\n",
    "    output_dir=r\".../Data_result/MGWR\",\n",
    "    multi=True, fixed=False, kernel=\"bisquare\", spherical=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "408a600d-1ddf-4866-a0f9-bebde2049d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics_df).to_csv(r\"D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/MGWR/_MGWR_metrics_all.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b55ada8d-aeb6-4939-b01d-839c655cffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_n_regions_from_bic(bic_path: str) -> int:\n",
    "    df = pd.read_csv(bic_path, sep=\"\\t\")\n",
    "    row = df.sort_values([\"MSE\", \"n_regions\"], kind=\"mergesort\").iloc[0]\n",
    "    return int(row[\"n_regions\"])\n",
    "\n",
    "def run_km_with_best_bic(\n",
    "    data_dir: str,\n",
    "    files: list[str],\n",
    "    bic_dir: str,\n",
    "    bic_suffix: str = \"_km.txt\",\n",
    "    out_dir: str = r\"...\\Data_result\\sim_best\",\n",
    "    min_region: int = 20,\n",
    "    save_region_label: bool = False,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for fname in files:\n",
    "        stem = os.path.splitext(fname)[0]\n",
    "        bic_path = os.path.join(bic_dir, f\"{stem}{bic_suffix}\")\n",
    "        R = best_n_regions_from_bic(bic_path)\n",
    "        if verbose:\n",
    "            print(f\"[KM] {fname} → best n_regions={R}  (BIC from: {bic_path})\")\n",
    "        results, rcoeff, rlabel, coefs = run_kmodels(\n",
    "            data_dir=data_dir,\n",
    "            file_names=[fname],\n",
    "            n_regions=R,\n",
    "            micro_clusters=2 * R,\n",
    "            min_region=min_region,\n",
    "            save_region_label=save_region_label,\n",
    "            verbose=verbose,\n",
    "            output_dir=out_dir,\n",
    "        )\n",
    "        df = pd.read_csv(os.path.join(data_dir, fname), sep=\"\\t\")\n",
    "\n",
    "        X = df[[\"feat1\", \"feat2\"]].to_numpy()\n",
    "        y = df[\"y\"].to_numpy()\n",
    "        Xarr = np.hstack([np.ones((len(y), 1)), X])\n",
    "        Yarr = y\n",
    "        \n",
    "        bic, r_2, k, MSE = get_bic_r2(Xarr, Yarr, rlabel, rcoeff)\n",
    "                                \n",
    "        if verbose:\n",
    "            print(f\"{fname} | n_regions={R:2d} ( BIC={bic:.6f} R2={r_2:.6f} SSE={MSE:.6f} \")\n",
    "\n",
    "def run_skater_with_best_bic(\n",
    "    data_dir: str,\n",
    "    files: list[str],\n",
    "    bic_dir: str,\n",
    "    bic_suffix: str = \"_sk.txt\",\n",
    "    out_dir: str = r\"...\\Data_result\\sim_best\",\n",
    "    quorum: int = 20,\n",
    "    save_region_label: bool = False,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for fname in files:\n",
    "        stem = os.path.splitext(fname)[0]\n",
    "        bic_path = os.path.join(bic_dir, f\"{stem}{bic_suffix}\")\n",
    "        R = best_n_regions_from_bic(bic_path)\n",
    "        if verbose:\n",
    "            print(f\"[SK] {fname} → best n_regions={R}  (BIC from: {bic_path})\")\n",
    "\n",
    "        run_skreg(\n",
    "            data_dir=data_dir,\n",
    "            file_names=[fname],\n",
    "            n_regions=R,\n",
    "            quorum=quorum,\n",
    "            save_region_label=save_region_label,\n",
    "            output_dir=out_dir,\n",
    "            verbose=verbose,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d01cc08a-a62e-4d09-b2da-7a7120c107f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KM] df_con_uni.txt → best n_regions=10  (BIC from: D:/wanghanbin/Linear Regression Tree/code/comparision_paper/BIC/km\\df_con_uni_km.txt)\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/sim_best/uni\\df_con_uni_KM_result.txt\n",
      "df_con_uni.txt | n_regions=10 ( BIC=1270.775105 R2=0.828133 SSE=1.513495 \n",
      "[KM] df_discon_uni.txt → best n_regions=9  (BIC from: D:/wanghanbin/Linear Regression Tree/code/comparision_paper/BIC/km\\df_discon_uni_km.txt)\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/sim_best/uni\\df_discon_uni_KM_result.txt\n",
      "df_discon_uni.txt | n_regions= 9 ( BIC=4044.993263 R2=0.825184 SSE=4.634358 \n",
      "[KM] df_multi_uni.txt → best n_regions=8  (BIC from: D:/wanghanbin/Linear Regression Tree/code/comparision_paper/BIC/km\\df_multi_uni_km.txt)\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/sim_best/uni\\df_multi_uni_KM_result.txt\n",
      "df_multi_uni.txt | n_regions= 8 ( BIC=3558.679676 R2=0.798123 SSE=3.851108 \n",
      "[KM] df_vor_uni.txt → best n_regions=5  (BIC from: D:/wanghanbin/Linear Regression Tree/code/comparision_paper/BIC/km\\df_vor_uni_km.txt)\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/sim_best/uni\\df_vor_uni_KM_result.txt\n",
      "df_vor_uni.txt | n_regions= 5 ( BIC=4496.108704 R2=0.839791 SSE=5.763236 \n"
     ]
    }
   ],
   "source": [
    "data_dir = r\".../Data_gen\"\n",
    "files = [\n",
    "    \"df_con_uni.txt\",\n",
    "    #\"df_con_grf.txt\",\n",
    "    \"df_discon_uni.txt\",\n",
    "    #\"df_discon_grf.txt\",\n",
    "    \"df_multi_uni.txt\",\n",
    "    #\"df_multi_grf.txt\",\n",
    "    #\"df_vor_grf.txt\",\n",
    "    \"df_vor_uni.txt\"\n",
    "]\n",
    "\n",
    "bic_dir_km = r\"D:/wanghanbin/Linear Regression Tree/code/comparision_paper/BIC/km\"\n",
    "bic_dir_sk = r\"D:/wanghanbin/Linear Regression Tree/code/comparision_paper/BIC/sk\"\n",
    "\n",
    "out_dir = r\"D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/sim_best/uni\"\n",
    "\n",
    "run_km_with_best_bic(\n",
    "    data_dir=data_dir,\n",
    "    files=files,\n",
    "    bic_dir=bic_dir_km,\n",
    "    bic_suffix=\"_km.txt\",\n",
    "    out_dir=out_dir,\n",
    "    min_region=20,\n",
    "    save_region_label=False,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "344c2075-5fec-4443-b343-40dca0670e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SK] df_con_uni.txt → best n_regions=7  (BIC from: D:/wanghanbin/Linear Regression Tree/code/comparision_paper/BIC/sk\\df_con_uni_skreg.txt)\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/sim_best/uni\\df_con_uni_SKREG_result.txt\n",
      "[SK] df_discon_uni.txt → best n_regions=10  (BIC from: D:/wanghanbin/Linear Regression Tree/code/comparision_paper/BIC/sk\\df_discon_uni_skreg.txt)\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/sim_best/uni\\df_discon_uni_SKREG_result.txt\n",
      "[SK] df_multi_uni.txt → best n_regions=8  (BIC from: D:/wanghanbin/Linear Regression Tree/code/comparision_paper/BIC/sk\\df_multi_uni_skreg.txt)\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/sim_best/uni\\df_multi_uni_SKREG_result.txt\n",
      "[SK] df_vor_uni.txt → best n_regions=6  (BIC from: D:/wanghanbin/Linear Regression Tree/code/comparision_paper/BIC/sk\\df_vor_uni_skreg.txt)\n",
      "[OK] D:/wanghanbin/Linear Regression Tree/code/comparision_paper/Data_result/sim_best/uni\\df_vor_uni_SKREG_result.txt\n"
     ]
    }
   ],
   "source": [
    "run_skater_with_best_bic(\n",
    "    data_dir=data_dir,\n",
    "    files=files,\n",
    "    bic_dir=bic_dir_sk,\n",
    "    bic_suffix=\"_skreg.txt\",\n",
    "    out_dir=out_dir,\n",
    "    quorum=20,\n",
    "    save_region_label=False,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2456eb49-f1dd-4ea9-b19e-6834b537a520",
   "metadata": {},
   "source": [
    "# Empirical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2ffe9-2cac-4ad0-a6eb-fe7ec7a17a03",
   "metadata": {},
   "source": [
    "# Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a87665f-8fa9-4312-81bf-bf028fefc34a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "HTTP response code: 301",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m vote_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwanghanbin\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLinear Regression Tree\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcomparision_paper\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEmpirical_test\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvote_std.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m df_vote \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(vote_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcounty_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m us_county \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://raw.github.com/Ziqi-Li/gis5122/master/data/us_counties.geojson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m us_county \u001b[38;5;241m=\u001b[39m us_county\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcounty_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m poly \u001b[38;5;241m=\u001b[39m us_county\u001b[38;5;241m.\u001b[39mmerge(df_vote[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcounty_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcounty_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Program Files\\Python 3.12.4\\Lib\\site-packages\\geopandas\\io\\file.py:294\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m             from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[1;32mD:\\Program Files\\Python 3.12.4\\Lib\\site-packages\\geopandas\\io\\file.py:547\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[1;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    544\u001b[0m     )\n\u001b[0;32m    545\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Program Files\\Python 3.12.4\\Lib\\site-packages\\pyogrio\\geopandas.py:265\u001b[0m, in \u001b[0;36mread_dataframe\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[0;32m    285\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mD:\\Program Files\\Python 3.12.4\\Lib\\site-packages\\pyogrio\\raw.py:198\u001b[0m, in \u001b[0;36mread\u001b[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:1240\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyogrio\\\\_io.pyx:220\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDataSourceError\u001b[0m: HTTP response code: 301"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from libpysal.weights import Queen, Rook\n",
    "\n",
    "vote_path = r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\Data\\vote_std.txt\"\n",
    "df_vote = pd.read_csv(vote_path, sep=\"\\t\").sort_values(\"county_id\").reset_index(drop=True)\n",
    "\n",
    "us_county = gpd.read_file(\"https://raw.github.com/Ziqi-Li/gis5122/master/data/us_counties.geojson\")\n",
    "us_county = us_county.sort_values(\"county_id\").reset_index(drop=True)\n",
    "\n",
    "poly = us_county.merge(df_vote[[\"county_id\"]], on=\"county_id\", how=\"inner\")\n",
    "\n",
    "w_q = Rook.from_dataframe(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12543ad4-2b49-4bf4-9ee4-c94f5d2dbd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~pd.Series(range(len(poly))).isin(islands)\n",
    "poly = poly.loc[mask].reset_index(drop=True)\n",
    "df_vote = df_vote.loc[mask].reset_index(drop=True)\n",
    "\n",
    "w_q = Rook.from_dataframe(poly, use_index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a3ba82f-1f78-44d5-ab11-b5f7aaf6a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vote.to_csv(r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\Data\\vote_std_rook.txt\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b5495-ea96-404c-be06-485d88355019",
   "metadata": {},
   "source": [
    "## KM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d59d8a5b-a70d-4049-9b3e-8261087d2893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmodels_empirical(\n",
    "    df,\n",
    "    *,\n",
    "    y_col: str = \"new_pct_dem\",\n",
    "    w,\n",
    "    feature_cols: Sequence[str] = (\n",
    "        \"proj_X\",\"proj_Y\",\"pct_black\",\"pct_hisp\",\"pct_bach\",\n",
    "        \"median_income\",\"ln_pop_den\",\"pct_3rd_party\",\"pct_fb\"\n",
    "    ),\n",
    "    coord_cols: Tuple[str, str] = (\"proj_X\",\"proj_Y\"),\n",
    "    n_regions: int = 20,\n",
    "    min_region: int = 50,\n",
    "    micro_clusters: Optional[int] = None,\n",
    "    k_neighbors: int = 8,\n",
    "    standardize: bool = True,\n",
    "    save_region_label: bool = True,\n",
    "    out_path: Optional[str] = None\n",
    ") -> pd.DataFrame:\n",
    "    n = len(df)\n",
    "\n",
    "    X_feat = df.loc[:, feature_cols].to_numpy(dtype=float)\n",
    "    y_raw  = df.loc[:, y_col].to_numpy(dtype=float).ravel()\n",
    "    coords = df.loc[:, coord_cols].to_numpy(dtype=float)\n",
    "\n",
    "    if standardize:\n",
    "        sx = StandardScaler().fit(X_feat)\n",
    "        sy = StandardScaler().fit(y_raw.reshape(-1,1))\n",
    "        X_std = sx.transform(X_feat)\n",
    "        y_std = sy.transform(y_raw.reshape(-1,1)).ravel()\n",
    "        Xarr  = np.hstack([np.ones((n,1)), X_std])\n",
    "        Yarr  = y_std\n",
    "    else:\n",
    "        Xarr = np.hstack([np.ones((n,1)), X_feat])\n",
    "        Yarr = y_raw\n",
    "        sx = sy = None\n",
    "\n",
    "    p = Xarr.shape[1]  # = 1 + len(feature_cols)\n",
    "\n",
    "    if micro_clusters is None:\n",
    "        micro_clusters = 2 * n_regions\n",
    "    clabel, _ = kmodels(Xarr, Yarr, micro_clusters, w,\n",
    "                        init_stoc_step=False, verbose=False)\n",
    "    slabel = split_components(w, clabel)\n",
    "    rlabel, rcoeff, _ = greedy_merge(\n",
    "        Xarr, Yarr, n_regions, w, slabel,\n",
    "        min_size=min_region, verbose=False\n",
    "    )\n",
    "    \n",
    "    bic, r2,_,_ = get_bic_r2(Xarr, Yarr, rlabel, rcoeff)\n",
    "\n",
    "    beta_mat_std = np.vstack([rcoeff[int(lb)] for lb in rlabel])  # (n, p)\n",
    "    b_std = beta_mat_std[:, 0]\n",
    "    A_std = beta_mat_std[:, 1:]  # (n, m)\n",
    "\n",
    "    df_out = df.copy()\n",
    "    df_out[\"b_result_std\"] = b_std\n",
    "    for j, name in enumerate(feature_cols):\n",
    "        df_out[f\"{name}_coef_std\"] = A_std[:, j]\n",
    "\n",
    "    df_out[\"b_result\"] = df_out[\"b_result_std\"]\n",
    "    for j, name in enumerate(feature_cols):\n",
    "        df_out[f\"{name}_coef\"] = df_out[f\"{name}_coef_std\"]\n",
    "\n",
    "    if save_region_label:\n",
    "        df_out[\"region_label\"] = rlabel\n",
    "\n",
    "    if out_path:\n",
    "        # stem = os.path.splitext(os.path.basename(data_path))[0]\n",
    "        # out_path = os.path.join(os.path.dirname(data_path), f\"{stem}_KM_result.txt\")\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        df_out.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "        print(f\"[OK] {out_path}\")\n",
    "    print(f\"BIC: {bic},  R2: {r2}\")\n",
    "    return df_out, bic, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d427951d-b5bf-4f03-b6bd-c0d584c901f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_path = r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\Data\\vote_std.txt\"\n",
    "df_vote = pd.read_csv(vote_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f737cdd6-ba58-4b8b-833f-a9093c530371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\Result\\vote_KM_result.txt\n",
      "BIC: -5680.265801014073,  R2: 0.8793686413909702\n"
     ]
    }
   ],
   "source": [
    "df_km,bic,r2 = run_kmodels_empirical(\n",
    "    df = df_vote,\n",
    "    y_col     = \"new_pct_dem\",\n",
    "    w = w_q,\n",
    "    feature_cols = [\n",
    "        \"pct_black\",\"pct_hisp\",\"pct_bach\",\n",
    "        \"median_income\",\"ln_pop_den\",\"pct_3rd_party\",\"pct_fb\"\n",
    "    ],\n",
    "    coord_cols    = (\"proj_X\",\"proj_Y\"),\n",
    "    n_regions     = 14,\n",
    "    min_region    = 20,\n",
    "    micro_clusters= None,\n",
    "    k_neighbors   = 4,\n",
    "    standardize   = False,\n",
    "    save_region_label = True,\n",
    "    out_path = r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\Result\\vote_KM_result.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84456588-2b48-44ce-9b14-d80fb948cea4",
   "metadata": {},
   "source": [
    "## SK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c5103587-8ac6-4ee8-a6a8-239b04c4b9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\Result\\vote_SKREG_result.txt\n"
     ]
    }
   ],
   "source": [
    "out_dir   = r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\Result\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "#df = pd.read_csv(vote_path, sep=\"\\t\")\n",
    "df = df_vote\n",
    "y_col       = \"new_pct_dem\"\n",
    "feature_cols = [\n",
    "    \"pct_black\",\"pct_hisp\",\"pct_bach\",\n",
    "    \"median_income\",\"ln_pop_den\",\"pct_3rd_party\",\"pct_fb\"\n",
    "]\n",
    "coord_cols  = (\"proj_X\",\"proj_Y\")   \n",
    "n_regions   = 20\n",
    "quorum      = 20\n",
    "knn_k       = 8\n",
    "\n",
    "coords = df.loc[:, coord_cols].to_numpy()\n",
    "w = weights.KNN.from_array(coords, k=knn_k)\n",
    "w = w.symmetrize()\n",
    "\n",
    "X = df_vote[feature_cols].to_numpy()\n",
    "y = df_vote[y_col].to_numpy()\n",
    "\n",
    "skater = Skater_reg()\n",
    "res = skater.fit(\n",
    "    n_regions,\n",
    "    w_q,\n",
    "    X,                                 \n",
    "    {\"reg\": PYSAL_OLS, \"y\": y, \"x\": X},\n",
    "    quorum=quorum\n",
    ")\n",
    "labels = res._trace[-1][0].astype(int)\n",
    "\n",
    "region_coefs = {}\n",
    "for r in np.unique(labels):\n",
    "    idx = (labels == r)\n",
    "    Xr, yr = X[idx, :], y[idx]\n",
    "    lr = LinearRegression(fit_intercept=True).fit(Xr, yr)\n",
    "    region_coefs[r] = (lr.intercept_, lr.coef_)  # (b, array of betas)\n",
    "\n",
    "b_vec  = np.array([region_coefs[int(lb)][0] for lb in labels])\n",
    "B_mat  = np.vstack([region_coefs[int(lb)][1] for lb in labels])   # (N, p)\n",
    "\n",
    "df_out = df_vote.copy()\n",
    "df_out[\"region_label\"] = labels\n",
    "df_out[\"b_result\"]     = b_vec\n",
    "for j, f in enumerate(feature_cols):\n",
    "    df_out[f\"{f}_coef\"] = B_mat[:, j]\n",
    "\n",
    "out_path = os.path.join(out_dir, f\"vote_SKREG_result.txt\")\n",
    "df_out.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "print(\"[OK]\", out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d32c694-132b-4b81-8787-a2ed5c354866",
   "metadata": {},
   "source": [
    "# SCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f9eae-1d74-44c8-93b8-5ba061d60304",
   "metadata": {},
   "source": [
    "# SCC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c490aec9-60e5-4c7f-b36d-f52cbe342d88",
   "metadata": {},
   "source": [
    "## MGWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904c3ca-8dd5-41c9-abf9-87c5069c960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path  = r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\Data\\vote_std_rook.txt\"\n",
    "out_path = r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\Result\\vote_MGWR_result_2.txt\"\n",
    "\n",
    "y_col       = \"new_pct_dem\"\n",
    "coord_cols  = (\"proj_X\", \"proj_Y\")\n",
    "feature_cols = [\n",
    "    \"pct_black\", \"pct_hisp\", \"pct_bach\",\n",
    "    \"median_income\", \"ln_pop_den\",\n",
    "    \"pct_3rd_party\", \"pct_fb\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(in_path, sep=\"\\t\")\n",
    "coords = df.loc[:, coord_cols].to_numpy()\n",
    "y = df.loc[:, y_col].to_numpy().reshape(-1, 1)\n",
    "X = df.loc[:, feature_cols].to_numpy()\n",
    "\n",
    "n = len(df)\n",
    "\n",
    "selector = Sel_BW(\n",
    "    coords, y, X,\n",
    "    multi=True,\n",
    "    fixed=False,\n",
    "    kernel=\"bisquare\",\n",
    "    spherical=False,\n",
    "    constant=True,  \n",
    "    #n_jobs=1\n",
    ")\n",
    "selector.search()\n",
    "\n",
    "model = MGWR(\n",
    "    coords, y, X, selector,\n",
    "    fixed=False, kernel=\"bisquare\", spherical=False,\n",
    "    constant=True, #n_jobs=1\n",
    ")\n",
    "res = model.fit()\n",
    "\n",
    "params = res.params\n",
    "df_out = df.copy()\n",
    "df_out[\"intercept\"] = params[:, 0]\n",
    "for j, f in enumerate(feature_cols, start=1):\n",
    "    df_out[f\"{f}_coef\"] = params[:, j]\n",
    "\n",
    "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "df_out.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "print(f\"[OK] {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9559da2-17af-4f0c-8b3d-63903ace1190",
   "metadata": {},
   "source": [
    "## Sig_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab104a-27cc-46ac-b580-93d6b9044c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\Result\\vote_KM_result.txt\",sep=\"\\t\")\n",
    "\n",
    "y_col = \"new_pct_dem\"\n",
    "x_cols = [\"pct_black\",\"pct_hisp\",\"pct_bach\",\n",
    "          \"median_income\",\"ln_pop_den\",\"pct_3rd_party\",\"pct_fb\"]\n",
    "g_col = \"region_label\"\n",
    "alpha = 0.05/14\n",
    "\n",
    "coef_cols = [\"b_result\"] + [f\"{x}_coef\" for x in x_cols]\n",
    "\n",
    "for g, sub in df.groupby(g_col):\n",
    "    idx = sub.index\n",
    "    sub = sub.dropna(subset=[y_col] + x_cols)\n",
    "\n",
    "    if len(sub) <= len(x_cols) + 1:\n",
    "        df.loc[idx, coef_cols] = np.nan\n",
    "        continue\n",
    "\n",
    "    X = sm.add_constant(sub[x_cols].to_numpy(), has_constant=\"add\")\n",
    "    y = sub[y_col].to_numpy()\n",
    "    res = sm.OLS(y, X).fit()\n",
    "\n",
    "    coefs = dict(zip(coef_cols, res.params))\n",
    "    pvals = dict(zip(coef_cols, res.pvalues))\n",
    "\n",
    "    for c in coef_cols:\n",
    "        if pvals[c] >= alpha:\n",
    "            coefs[c] = np.nan\n",
    "        df.loc[idx, c] = coefs[c]\n",
    "\n",
    "out_path = r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\Result\\vote_KM_result_sig.txt\"\n",
    "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "df.to_csv(out_path, sep=\"\\t\", index=False, float_format=\"%.6f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834eed2-a36d-4d66-afca-ab9469a9d205",
   "metadata": {},
   "source": [
    "# EM BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af8faf15-ecd7-495c-8ac0-157153976726",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = r\"...\\Empirical_test\\BIC\\km_bic_r2_2.txt\"\n",
    "Yarr = df_vote[\"new_pct_dem\"].to_numpy(dtype=float).ravel()\n",
    "Xarr = df_vote[[\"pct_black\",\"pct_hisp\",\"pct_bach\",\"median_income\",\"ln_pop_den\",\"pct_3rd_party\",\"pct_fb\"]].to_numpy(dtype=float)\n",
    "coords = df_vote[[\"proj_X\",\"proj_Y\"]]\n",
    "# w = weights.KNN(coords, k=8)\n",
    "# w = w.symmetrize()\n",
    "w = w_q\n",
    "n_min = 2\n",
    "n_max = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2468ab89-355e-4260-8d3f-0eb1d11f064d",
   "metadata": {},
   "source": [
    "## KM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d51d745a-eaa4-4c09-8d46-262232769f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_regions= 2 (K_micro= 4)  BIC=-3704.587803  R2=0.710834\n",
      "n_regions= 3 (K_micro= 6)  BIC=-4538.979783  R2=0.784605\n",
      "n_regions= 4 (K_micro= 8)  BIC=-4856.713269  R2=0.810519\n",
      "n_regions= 5 (K_micro=10)  BIC=-4996.411475  R2=0.823482\n",
      "n_regions= 6 (K_micro=12)  BIC=-5254.605333  R2=0.841714\n",
      "n_regions= 7 (K_micro=14)  BIC=-5327.737506  R2=0.849348\n",
      "n_regions= 8 (K_micro=16)  BIC=-5450.285102  R2=0.858878\n",
      "n_regions= 9 (K_micro=18)  BIC=-5401.390258  R2=0.860302\n",
      "n_regions=10 (K_micro=20)  BIC=-5529.163567  R2=0.869359\n",
      "n_regions=11 (K_micro=22)  BIC=-5607.189187  R2=0.875856\n",
      "n_regions=12 (K_micro=24)  BIC=-5678.556657  R2=0.881776\n",
      "n_regions=13 (K_micro=26)  BIC=-5550.745955  R2=0.879958\n",
      "n_regions=14 (K_micro=28)  BIC=-5651.112494  R2=0.886746\n",
      "n_regions=15 (K_micro=30)  BIC=-5507.829956  R2=0.884430\n",
      "n_regions=16 (K_micro=32)  BIC=-5545.679188  R2=0.888747\n",
      "n_regions=17 (K_micro=34)  BIC=-5545.143489  R2=0.891572\n",
      "n_regions=18 (K_micro=36)  BIC=-5453.166755  R2=0.891167\n",
      "n_regions=19 (K_micro=38)  BIC=-5348.721422  R2=0.890322\n",
      "n_regions=20 (K_micro=40)  BIC=-5398.444352  R2=0.894822\n",
      "[OK] 写出：D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\BIC\\km_bic_r2_2.txt\n"
     ]
    }
   ],
   "source": [
    "Xarr = np.hstack([np.ones((len(Yarr), 1)), Xarr])\n",
    "rows = []\n",
    "for n_regions in range(n_min, n_max+1):  # 2..20\n",
    "    K_micro = 2 * n_regions\n",
    "    clabel, _ = kmodels(Xarr, Yarr, K_micro, w, init_stoc_step=False, verbose=False)\n",
    "    slabel     = split_components(w, clabel)\n",
    "    rlabel, rcoeff, _ = greedy_merge(\n",
    "        Xarr, Yarr, n_regions, w, slabel, min_size=20, verbose=False)\n",
    "\n",
    "    bic, r2, _, _ = get_bic_r2(Xarr, Yarr, rlabel, rcoeff)\n",
    "\n",
    "    rows.append({\"n_regions\": n_regions, \"BIC\": bic, \"R2\": r2})\n",
    "    print(f\"n_regions={n_regions:2d} (K_micro={K_micro:2d})  BIC={bic:.6f}  R2={r2:.6f}\")\n",
    "\n",
    "df_out = pd.DataFrame(rows).sort_values(\"n_regions\")\n",
    "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "df_out.to_csv(out_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c7137c-6601-4ad1-bc7f-1ff0a669960b",
   "metadata": {},
   "source": [
    "## SK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a10f920d-191b-4386-92ea-9140f732943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skater = Skater_reg()\n",
    "Yarr = df_vote[\"new_pct_dem\"]\n",
    "result = skater.fit(n_max, w_q, Xarr, {\"reg\": PYSAL_OLS, \"y\": Yarr, \"x\": Xarr},quorum = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4043c01-c150-4d10-977e-37fc5704ac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_regions= 2 BIC=-3872.133946  R2=0.727434\n",
      "n_regions= 3 BIC=-4031.308427  R2=0.748321\n",
      "n_regions= 4 BIC=-4199.540027  R2=0.768284\n",
      "n_regions= 5 BIC=-4279.837831  R2=0.780537\n",
      "n_regions= 6 BIC=-4367.605563  R2=0.792642\n",
      "n_regions= 7 BIC=-4445.956575  R2=0.803484\n",
      "n_regions= 8 BIC=-4532.093230  R2=0.814225\n",
      "n_regions= 9 BIC=-4601.878289  R2=0.823453\n",
      "n_regions=10 BIC=-4624.566949  R2=0.829658\n",
      "n_regions=11 BIC=-4640.197712  R2=0.835272\n",
      "n_regions=12 BIC=-4652.035163  R2=0.840506\n",
      "n_regions=13 BIC=-4665.449540  R2=0.845652\n",
      "n_regions=14 BIC=-4675.156027  R2=0.850453\n",
      "n_regions=15 BIC=-4678.078415  R2=0.854789\n",
      "n_regions=16 BIC=-4724.848526  R2=0.860975\n",
      "n_regions=17 BIC=-4759.894885  R2=0.866394\n",
      "n_regions=18 BIC=-4767.804405  R2=0.870476\n",
      "n_regions=19 BIC=-4769.568014  R2=0.874184\n",
      "n_regions=20 BIC=-4755.531290  R2=0.877162\n"
     ]
    }
   ],
   "source": [
    "keep = {}\n",
    "for rec in result._trace:\n",
    "    labels = np.asarray(rec[0])\n",
    "    K = np.unique(labels).size\n",
    "    if 2 <= K <= n_max:\n",
    "        keep[K] = labels\n",
    "\n",
    "rows = []\n",
    "for n_region in sorted(keep):\n",
    "    bic, r2,_ = get_bic_r2_sk(keep[n_region], Xarr, Yarr)\n",
    "    rows.append((n_region, bic, r2))\n",
    "    print(f\"n_regions={n_region:2d} BIC={bic:.6f}  R2={r2:.6f}\")\n",
    "\n",
    "df_out = pd.DataFrame(rows, columns=[\"n_regions\", \"BIC\", \"R2\"]).sort_values(\"n_regions\")\n",
    "df_out.to_csv(r\"D:\\wanghanbin\\Linear Regression Tree\\code\\comparision_paper\\Empirical_test\\BIC\\skreg_bic_r2_2.txt\" , sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d691b4d-01d5-4af8-9eed-87c4f70a7ec2",
   "metadata": {},
   "source": [
    "## MGWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607cd1f0-0310-4ca2-9bdc-384dc177a93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
